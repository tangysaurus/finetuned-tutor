{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install torch transformers datasets accelerate peft trl\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "TYyk82uKOLFk",
        "collapsed": true
      },
      "id": "TYyk82uKOLFk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess MathDial dataset for finetuning"
      ],
      "metadata": {
        "id": "taQrJ8hOcR04"
      },
      "id": "taQrJ8hOcR04"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ff724d55",
      "metadata": {
        "id": "ff724d55"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from datasets import load_dataset, Dataset\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "import re\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7e519d00",
      "metadata": {
        "id": "7e519d00"
      },
      "outputs": [],
      "source": [
        "HUGGING_FACE_ACCESS_TOKEN = userdata.get('HUGGING_FACE_ACCESS_TOKEN')\n",
        "login(token = HUGGING_FACE_ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58cc5c38",
      "metadata": {
        "id": "58cc5c38"
      },
      "outputs": [],
      "source": [
        "# load MathDial dataset\n",
        "tutor_dialogue = load_dataset(\"eth-nlped/mathdial\")\n",
        "tutor_train = tutor_dialogue[\"train\"].to_pandas()\n",
        "tutor_test = tutor_dialogue[\"test\"].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "13ffc28a",
      "metadata": {
        "id": "13ffc28a"
      },
      "outputs": [],
      "source": [
        "def extract_move(sentence: str):\n",
        "    \"\"\"extract teacher moves (probing, focus, telling, generic)\"\"\"\n",
        "    pattern = r\"\\b(probing|focus|telling|generic)\\b\"\n",
        "    match = re.search(rf\"\\({pattern}\\)\", sentence)\n",
        "\n",
        "    if match:\n",
        "        clean_sentence = re.sub(rf\"\\({pattern}\\)\", \"\", sentence)\n",
        "        return clean_sentence, match.group(1)\n",
        "\n",
        "    else:\n",
        "        return sentence, None\n",
        "\n",
        "def remove_names(sentence: str, student_name: str):\n",
        "    \"\"\"remove names from conversation\"\"\"\n",
        "    pattern = rf\"\\b(Teacher|Student|{student_name})\\b\"\n",
        "    match = re.search(rf\"{pattern}: \", sentence)\n",
        "\n",
        "    if match:\n",
        "        clean_sentence = re.sub(rf\"{pattern}: \", \"\", sentence)\n",
        "        return clean_sentence, match.group(1)\n",
        "\n",
        "    else:\n",
        "        return sentence, None\n",
        "\n",
        "def preprocess(conversation: str):\n",
        "    \"\"\"split conversation into turns\"\"\"\n",
        "\n",
        "    moves = []\n",
        "    split_conversation = conversation.split(\"|EOM|\")\n",
        "\n",
        "    for i in range(len(split_conversation)):\n",
        "        clean_sentence, move = extract_move(split_conversation[i])\n",
        "        split_conversation[i] = clean_sentence\n",
        "\n",
        "        if move:\n",
        "            moves.append(move)\n",
        "\n",
        "    split_conversation = list(filter(None, split_conversation))\n",
        "    return split_conversation, moves\n",
        "\n",
        "def format_conversation(\n",
        "        split_conversation: list[str],\n",
        "        moves: list[str],\n",
        "        system_prompt: str,\n",
        "        incorrect_solution: str,\n",
        "        student_name: str\n",
        "    ):\n",
        "    \"\"\"\n",
        "    formats conversation into the following structure:\n",
        "    '{\"messages\": [{\"role\": \"user\", \"content\": \"What color is the sky?\"}, {\"role\": \"assistant\", \"content\": \"It is blue.\"}]}'\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": incorrect_solution}\n",
        "                ]\n",
        "\n",
        "    move_index = 0\n",
        "\n",
        "    for i in range(len(split_conversation)):\n",
        "        clean_sentence, match = remove_names(split_conversation[i], student_name)\n",
        "        if not clean_sentence or not match:\n",
        "            continue\n",
        "\n",
        "        if match == \"Teacher\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"[{moves[move_index].upper()}] \" + clean_sentence})\n",
        "            move_index += 1\n",
        "\n",
        "        else:\n",
        "            messages.append({\"role\": \"user\", \"content\": clean_sentence})\n",
        "\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d8856618",
      "metadata": {
        "id": "d8856618"
      },
      "outputs": [],
      "source": [
        "def build_system_prompt(question: str, ground_truth: str, student_name):\n",
        "    system_prompt = (\n",
        "        f\"\"\"\n",
        "        You are a mathematics teacher for students in elementary and middle school.\n",
        "        Your task is to help your student {student_name} solve a problem that they initially solved incorrectly.\n",
        "        You have access to the problem statement and ground truth solution, which are provided below.\n",
        "\n",
        "        Make sure to abide by the following guidelines:\n",
        "            1. Do NOT give away the answer immediately.\n",
        "            2. Lead the student toward the correct answer using the following strategies: focus, probing, telling, and generic.\n",
        "            3. Each of your responses should follow this structure: '[STRATEGY] one sentence response'\n",
        "            4. Keep responses concise (1–2 sentences), but long enough to be natural.\n",
        "            5. For each response, you will select only 1 strategy to use. You may switch strategies on different turns.\n",
        "            6. Ensure your selected strategy is displayed in all CAPS (e.g. [FOCUS])\n",
        "\n",
        "        Escalation rules:\n",
        "            - Start with [FOCUS] or [PROBING] strategies.\n",
        "            - Use [TELLING] (revealing strategy) only if the student is stuck after several turns.\n",
        "            - Use [TELLING] (revealing answer) only as a last resort after repeated failed attempts.\n",
        "            - If the student provides a correct answer, use [GENERIC] to give encouragement or praise before moving on.\n",
        "\n",
        "        Here is a description of each strategy, its intent/purpose, and an example of how that strategy is used for each intent:\n",
        "            1. focus\n",
        "                - intent 1: seek strategy (e.g. So what should you do next?)\n",
        "                - intent 2: guide student focus (e.g. Can you calculate...?)\n",
        "                - intent 3: recall relevant information (e.g. Can you reread the question and tell me what is...?)\n",
        "            2. probing\n",
        "                - intent 1: asking for explanation (e.g. Why do you think you need to add these numbers?)\n",
        "                - intent 2: seeking self correction (e.g. Are you sure you need to add here?)\n",
        "                - intent 3: perturbing the question (e.g. How would things change if they had ... items instead?)\n",
        "                - intent 4: seeking world knowledge (e.g. How do you calculate the perimeter of a square?)\n",
        "            3. telling\n",
        "                - intent 1: revealing strategy (e.g. You need to add ... to ... get your answer.)\n",
        "                - intent 2: revealing answer (e.g. No, he had ... items.)\n",
        "            4. generic\n",
        "                - intent 1: greeting/fairwell (e.g. Hi..., how are you doing with the word problem?, Good Job! Is there anything else I can help with?)\n",
        "                - intent 2: general inquiry (e.g. Can you go walk me through your solution?)\n",
        "\n",
        "        Example conversation:\n",
        "            your output: '[PROBING] If you had 4 of something and tripled that amount, how much would you have?'\n",
        "            student response: 'I would have 12 of something.'\n",
        "            your output: '[PROBING] So if Nancy triples the 18 cubic feet of water, how much would she have?'\n",
        "\n",
        "        Problem: {question}\n",
        "        Solution: {ground_truth}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    return system_prompt\n",
        "\n",
        "def get_student_name(student_profile: str):\n",
        "    return student_profile.split()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d745ff08",
      "metadata": {
        "id": "d745ff08"
      },
      "outputs": [],
      "source": [
        "def process_row(row):\n",
        "    \"\"\"Constructs a string of messages for each conversation\"\"\"\n",
        "    student_name = get_student_name(row[\"student_profile\"])\n",
        "    system_prompt = build_system_prompt(row[\"question\"], row[\"ground_truth\"], student_name)\n",
        "    split_conversation = preprocess(row[\"conversation\"])\n",
        "    messages = format_conversation(split_conversation[0], split_conversation[1], system_prompt, row[\"student_incorrect_solution\"], student_name)\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4e8218c9",
      "metadata": {
        "id": "4e8218c9"
      },
      "outputs": [],
      "source": [
        "tutor_train[\"messages\"] = tutor_train.apply(process_row, axis = 1)\n",
        "tutor_test[\"messages\"] = tutor_train.apply(process_row, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(tutor_train[[\"messages\"]])\n",
        "\n",
        "half = -math.ceil(len(tutor_test) / 2)\n",
        "\n",
        "tutor_validation = tutor_test[:half]\n",
        "tutor_test = tutor_test[half:]\n",
        "\n",
        "train = Dataset.from_pandas(tutor_train[[\"messages\"]])\n",
        "validation = Dataset.from_pandas(tutor_validation[[\"messages\"]])\n",
        "test = Dataset.from_pandas(tutor_test[[\"messages\"]])"
      ],
      "metadata": {
        "id": "U857lj_BNvis"
      },
      "id": "U857lj_BNvis",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetune Qwen2.5-Instruct using LoRA"
      ],
      "metadata": {
        "id": "g-G3MiCnc5Ek"
      },
      "id": "g-G3MiCnc5Ek"
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "2ftwdOwMOEPe"
      },
      "id": "2ftwdOwMOEPe",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "sJmGanSRQxMQ"
      },
      "id": "sJmGanSRQxMQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_dimension = 8\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.05\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r = rank_dimension,\n",
        "    lora_alpha = lora_alpha,\n",
        "    lora_dropout = lora_dropout,\n",
        "    bias = \"none\",\n",
        "    target_modules = [\"q_proj\", \"v_proj\"],\n",
        "    task_type = \"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "RGd7g8zzPrpm"
      },
      "id": "RGd7g8zzPrpm",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_func(example):\n",
        "    \"\"\"formats sequence of messages\"\"\"\n",
        "    return tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)"
      ],
      "metadata": {
        "id": "fSEnvua0Qt8Q"
      },
      "id": "fSEnvua0Qt8Q",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sft_config = SFTConfig(\n",
        "    output_dir = \"./results\",\n",
        "    logging_dir = \"./logs\",\n",
        "    num_train_epochs = 3,\n",
        "    per_device_train_batch_size = 8,\n",
        "    learning_rate = 2e-5,\n",
        "    warmup_ratio = 0.03,\n",
        "    weight_decay = 0.01,\n",
        "    save_strategy = \"steps\",\n",
        "    logging_steps = 10,\n",
        "    eval_strategy = \"steps\",\n",
        "    eval_steps = 200,\n",
        "    save_steps = 200,\n",
        "    max_length = 1024,\n",
        "    report_to=\"tensorboard\",\n",
        "    fp16 = True,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = train,\n",
        "    eval_dataset = validation,\n",
        "    args = sft_config,\n",
        "    peft_config = peft_config,\n",
        "    formatting_func = formatting_func\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"./results/final_model\")"
      ],
      "metadata": {
        "id": "S11BRbofQNPk"
      },
      "id": "S11BRbofQNPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "YJEAw-Vwboie"
      },
      "id": "YJEAw-Vwboie",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate fine-tuned model"
      ],
      "metadata": {
        "id": "C8BP2hgozK9I"
      },
      "id": "C8BP2hgozK9I"
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.predict(test)"
      ],
      "metadata": {
        "id": "9IpTe4FfzJQ2"
      },
      "id": "9IpTe4FfzJQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform inference using new adapter weights"
      ],
      "metadata": {
        "id": "JtjhTZwwxnXZ"
      },
      "id": "JtjhTZwwxnXZ"
    },
    {
      "cell_type": "code",
      "source": [
        "test[0]"
      ],
      "metadata": {
        "id": "2LF3pYhp4BTf"
      },
      "id": "2LF3pYhp4BTf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "adapter_path = \"results/final_model\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(model_name)\n",
        "base = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "model = PeftModel.from_pretrained(base, adapter_path)\n",
        "\n",
        "model = model.to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "test = {\"messages\":[{'content': \"\\n        You are a mathematics teacher for students in elementary and middle school.\\n        Your task is to help your student Alejandra solve a problem that they initially solved incorrectly.\\n        You have access to the problem statement and ground truth solution, which are provided below.\\n\\n        Make sure to abide by the following guidelines:\\n            1. Do NOT give away the answer immediately.\\n            2. Lead the student toward the correct answer using the following strategies: focus, probing, telling, and generic.\\n            3. Each of your responses should follow this structure: '[STRATEGY] one sentence response'\\n            4. Keep responses concise (1–2 sentences), but long enough to be natural.\\n            5. For each response, you will select only 1 strategy to use. You may switch strategies on different turns.\\n            6. Ensure your selected strategy is displayed in all CAPS (e.g. [FOCUS])\\n\\n        Escalation rules:\\n            - Start with [FOCUS] or [PROBING] strategies.\\n            - Use [TELLING] (revealing strategy) only if the student is stuck after several turns.\\n            - Use [TELLING] (revealing answer) only as a last resort after repeated failed attempts.\\n            - If the student provides a correct answer, use [GENERIC] to give encouragement or praise before moving on.\\n\\n        Here is a description of each strategy, its intent/purpose, and an example of how that strategy is used for each intent:\\n            1. focus\\n                - intent 1: seek strategy (e.g. So what should you do next?)\\n                - intent 2: guide student focus (e.g. Can you calculate...?)\\n                - intent 3: recall relevant information (e.g. Can you reread the question and tell me what is...?)\\n            2. probing\\n                - intent 1: asking for explanation (e.g. Why do you think you need to add these numbers?)\\n                - intent 2: seeking self correction (e.g. Are you sure you need to add here?)\\n                - intent 3: perturbing the question (e.g. How would things change if they had ... items instead?)\\n                - intent 4: seeking world knowledge (e.g. How do you calculate the perimeter of a square?)\\n            3. telling\\n                - intent 1: revealing strategy (e.g. You need to add ... to ... get your answer.)\\n                - intent 2: revealing answer (e.g. No, he had ... items.)\\n            4. generic\\n                - intent 1: greeting/fairwell (e.g. Hi..., how are you doing with the word problem?, Good Job! Is there anything else I can help with?)\\n                - intent 2: general inquiry (e.g. Can you go walk me through your solution?)\\n\\n        Example conversation:\\n            your output: '[PROBING] If you had 4 of something and tripled that amount, how much would you have?'\\n            student response: 'I would have 12 of something.'\\n            your output: '[PROBING] So if Nancy triples the 18 cubic feet of water, how much would she have?'\\n\\n        Problem: Haman’s father has an egg business supplying the local market. On a Wednesday morning, his father sends him to go and collect 10 trays of eggs for sale from their store. While loading the eggs into the car, he accidentally drops two trays. He calls his father telling him this, and is told to add 7 more trays for sale. How many eggs were sold that day?\\n        Solution: When Haman collected 10 trays and dropped 2 trays, he was left with 10 trays - 2 trays = 8 trays.\\nWhen he added 7 more trays, the total number of trays became 8 trays + 7 trays = 15 trays.\\nSince each tray contains 36 eggs, the total number of eggs to be sold is 36 eggs/tray * 15 trays = 540 eggs.\\n 540\\n        \",\n",
        "   'role': 'system'}, {'content': 'Haman originally had 10 trays of eggs, but he dropped 2, so he only had 10-2 = 8 trays left.\\nThen his father tells him to add 7 more trays, so he ends up with 8+7 = 15 trays in total.\\nAssuming each tray contains 30 eggs, then 15 trays would contain 15 x 30 = 450 eggs in total.\\nTherefore, 450 eggs were sold that day. \\n 450',\n",
        "  'role': 'user'}]}\n",
        "\n",
        "inputs = tokenizer(formatting_func(test), return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=128)\n",
        "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "i2LP44oNxFYp"
      },
      "id": "i2LP44oNxFYp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}